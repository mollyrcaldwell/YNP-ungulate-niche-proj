---
title: "YNP ungulate individual network metrics: week, month"
author: "Molly Caldwell"
date: "8/16/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, error = FALSE)
knitr::opts_knit$set(root.dir = "~/UWyo/PhD project/YNP-ungulate-niche-proj/")
```

```{r}
#load packages
library(sf)
library(mapview)
library(tidyverse)
library(dplyr)
library(lubridate)
library(spatsoc)
library(data.table)
library(asnipe)
library(igraph)
library(circlize)
library(ComplexHeatmap)
library(ggplot2)
library(GGally)
library(network)
library(sna)
library(maps)
library(ggnetwork)
library(ggpubr)
library(raster)
library(rgdal)
library(ggmap)
library(geosphere)
# if (!requireNamespace("BiocManager", quietly=TRUE))
#     install.packages("BiocManager")
# BiocManager::install("ComplexHeatmap")
library(ComplexHeatmap)
```

#Prep data

```{r}
#load seasonal gps data- all spp, 2 hr fixes
data_all <- readRDS("./Data/GPS data/Cleaned/allspp_cleanedGPSdata_seasonal_3.2022.rds")

#add week and month
data_all <- data_all %>%
  mutate(week = week(date)) %>% 
  mutate(id_yr_week = paste(cid, yr, week, sep = "_")) %>% 
  mutate(month = month(date)) %>% 
  mutate(id_yr_month = paste(cid, yr, month, sep = "_"))
```

```{r}
#define projection
proj <- st_crs(data_all)[[1]]

#split geometry into x y columns
data_xy <- data_all %>%
    mutate(x = unlist(purrr::map(data_all$geometry,1)),
           y = unlist(purrr::map(data_all$geometry,2)))

data_xy$geometry <- NULL
data_xy$date2 <- NULL

#convert data to data table for spatsoc
data_dt <- setDT(data_xy)

```

#Spatial network- by points (250 m, within 2 hours)

##Temporal grouping

```{r}
#temporal group with threshold of 2 hours
g_data <- group_times(DT = data_dt, datetime = 'date', threshold = "2 hours") #change hours depending on desired threshold
```

##Spatial grouping (points)

```{r}
#spatial group (by GPS points) with threshold 250 meters
group_pts(DT = g_data, threshold = 250, id = 'cid', 
                        coords = c('x', 'y'), timegroup = 'timegroup') #threshold units based on GPS data CRS
```

##Split data by id_yr_week and save as list

```{r}
#create year-season variable in grouped data to split ids in list
g_data <- g_data %>%
  mutate(yr_week = paste(yr, week, sep = "_"))

# Set number of items in the list, which corresponds to the number of unique year-seasons
N <- length(unique(g_data$yr_week))
N # 23 unique year-weeks

# Set vector with unique values of year-weeks
UID <- unique(g_data$yr_week)

# Create the empty list
gdata.list <- vector("list", N)
length(gdata.list) # Make sure there are indeed 23 items in the list!

# Store each yr_week as one item in the list
for (i in 1:length(UID)){
  
  print(i)
  
  gdata_UID <- g_data[(g_data$yr_week == UID[i]), ] # Group locations from each unique year-weekon
  gdata.list[[i]] <- gdata_UID # Store this subset of the data in the list
  
}
```

#Build observed networks- compute gambit of the group

```{r}
## Generate group by individual matrix
# The group column was previously generated by spatsoc::group_pts

# Create empty list
gbi.list <- vector("list", N)

for(i in 1:length(UID)) {
  print(i)
  gbiMtrx <- get_gbi(DT = gdata.list[[i]], group = 'timegroup', id = 'cid') # Create an individual matrix for each year-season
  gbi.list[[i]] <- gbiMtrx # Put each matrix in the list
}

# Example:
# Have a look at the first matrix, for our first year-week -
# it basically generates a matrix in which every row is a group, and each column indicates
# who was in the group (1) and who wasn't (0).
gbi.list[[1]]
```

```{r}
## Generate observed network (using asnipe::get_network)
# -> More info on the function here: https://rdrr.io/cran/asnipe/man/get_network.html
# -> Make sure that data_format == "GBI" (for gambit of the group)
# -> Here the association index is a simple ratio index, which is an association index that represents 
# the propensity for two elk to be observed in the same group, given that the group contains at least one of them (Farine & Whitehead, 2015).
# It is appropriate to use the SRI when building PBSNs, since all collared individuals are correctly identified 
# and observed at each relocation event (Robitaille et al., 2019). 

net.list <- vector("list", N)

for(i in 1:length(UID)) {
  print(i)
  net <- get_network(gbi.list[[i]],
                     data_format = "GBI",
                     association_index = "SRI")
  
  net.list[[i]] <- net 
}
```

#Calculate observed network metrics

```{r}
## Generate graph
# Here we're generating undirected and weighted networks from our matrices!
g.list <- vector("list", N)

for (i in 1:length(UID)){
  
  print(i)
  
  g <- graph.adjacency(net.list[[i]], 'undirected',
                       diag = FALSE, weighted = TRUE)
  g.list[[i]] <- g
}

# If you want to have a quick look at networks:
# (but note that we can't see edge weight here!)
plot(g.list[[1]]) 
```


```{r}
#Pull metrics from edges
edgeWeights.list <- vector("list", N)

for (i in 1:length(UID)){
  
  print(i)
  
  e <- get.data.frame(g.list[[i]])
  e$yr_week = paste(UID[i])
  edgeWeights.list[[i]] <- e
}

# Unlist all edge metrics (edgeWeights.list)
allEdges <- rbindlist(edgeWeights.list)

# Look at distribution of edge weights
hist(allEdges$weight) # Most of them close to 1.0!

# Save this! 
saveRDS(allEdges, "~/UWyo/PhD project/YNP-ungulate-niche-proj/Code output/individual_network_metrics/individual_edge_metrics_week.rds")
```

```{r}
#Pull metrics from nodes
# For more info on how to pull metrics from SNA: https://docs.ropensci.org/spatsoc/articles/using-in-sna.html

# Metrics:
# -> eigenvector centrality (with igraph): https://rdrr.io/cran/igraph/man/eigen_centrality.html
# -> eigenvector centrality - evcent() (with sna): https://www.rdocumentation.org/packages/sna/versions/2.6/topics/evcent
# -> strength (or weighted vertex degree): https://rdrr.io/cran/igraph/man/strength.html
# -> betweenness (with igraph): https://igraph.org/r/doc/betweenness.html
# -> betweenness (with sna): https://www.rdocumentation.org/packages/sna/versions/2.6/topics/betweenness

obs.list <- vector("list", N)

for (i in 1:length(UID)){
  
  print (i)
  
  observed <- data.table(
    
    centralityScaled = igraph::eigen_centrality(g.list[[i]], scale = TRUE)$vector, # Logical scalar, whether to scale the result to have a maximum score of one.
    centrality = igraph::eigen_centrality(g.list[[i]], scale = FALSE)$vector, # If no scaling is used then the result vector has unit length in the Euclidean norm.
    betweennessNorm = igraph::betweenness(g.list[[i]], normalized = TRUE), # If normalize = T, it seems like scores are rescaled such that they sum to 1.
    betweenness = igraph::betweenness(g.list[[i]], normalized = FALSE),
    strength = igraph::strength(g.list[[i]]), # The function graph.strength() also does the same thing!
    # Summing up the edge weights of the adjacent edges for each vertex. 
    # Be careful here, as this is relative to the number of collars that were out during that yr_seas!
    degree = igraph::degree(g.list[[i]]), # The degree of a vertex is its most basic structural property, the number of its adjacent edges.
    # Be careful here, as this is also relative to the number of collars that were out during that yr_seas!
    id = names(igraph::degree(g.list[[i]])),
    yr_week = paste(UID[i])
    
  )
  
  obs.list[[i]] <- observed
}

# Unlist all node metrics (obs.list)
allNodes <- rbindlist(obs.list)

# Look at distribution of some of the metrics:
hist(allNodes$centralityScaled)
hist(allNodes$strength)
hist(allNodes$degree)
hist(allNodes$betweennessNorm)

# Save this! 
saveRDS(allNodes, "~/UWyo/PhD project/YNP-ungulate-niche-proj/Code output/individual_network_metrics/individual_node_metrics_week.rds")
```

##Split data by id_yr_month and save as list

```{r}
#create year-season variable in grouped data to split ids in list
g_data <- g_data %>%
  mutate(yr_month = paste(yr, month, sep = "_"))

# Set number of items in the list, which corresponds to the number of unique year-seasons
N <- length(unique(g_data$yr_month))
N # 23 unique year-months

# Set vector with unique values of year-months
UID <- unique(g_data$yr_month)

# Create the empty list
gdata.list <- vector("list", N)
length(gdata.list) # Make sure there are indeed 23 items in the list!

# Store each yr_month as one item in the list
for (i in 1:length(UID)){
  
  print(i)
  
  gdata_UID <- g_data[(g_data$yr_month == UID[i]), ] # Group locations from each unique year-monthon
  gdata.list[[i]] <- gdata_UID # Store this subset of the data in the list
  
}
```

#Build observed networks- compute gambit of the group

```{r}
## Generate group by individual matrix
# The group column was previously generated by spatsoc::group_pts

# Create empty list
gbi.list <- vector("list", N)

for(i in 1:length(UID)) {
  print(i)
  gbiMtrx <- get_gbi(DT = gdata.list[[i]], group = 'timegroup', id = 'cid') # Create an individual matrix for each year-season
  gbi.list[[i]] <- gbiMtrx # Put each matrix in the list
}

# Example:
# Have a look at the first matrix, for our first year-month -
# it basically generates a matrix in which every row is a group, and each column indicates
# who was in the group (1) and who wasn't (0).
gbi.list[[1]]
```

```{r}
## Generate observed network (using asnipe::get_network)
# -> More info on the function here: https://rdrr.io/cran/asnipe/man/get_network.html
# -> Make sure that data_format == "GBI" (for gambit of the group)
# -> Here the association index is a simple ratio index, which is an association index that represents 
# the propensity for two elk to be observed in the same group, given that the group contains at least one of them (Farine & Whitehead, 2015).
# It is appropriate to use the SRI when building PBSNs, since all collared individuals are correctly identified 
# and observed at each relocation event (Robitaille et al., 2019). 

net.list <- vector("list", N)

for(i in 1:length(UID)) {
  print(i)
  net <- get_network(gbi.list[[i]],
                     data_format = "GBI",
                     association_index = "SRI")
  
  net.list[[i]] <- net 
}
```

#Calculate observed network metrics

```{r}
## Generate graph
# Here we're generating undirected and weighted networks from our matrices!
g.list <- vector("list", N)

for (i in 1:length(UID)){
  
  print(i)
  
  g <- graph.adjacency(net.list[[i]], 'undirected',
                       diag = FALSE, weighted = TRUE)
  g.list[[i]] <- g
}

# If you want to have a quick look at networks:
# (but note that we can't see edge weight here!)
plot(g.list[[1]]) 
```


```{r}
#Pull metrics from edges
edgeWeights.list <- vector("list", N)

for (i in 1:length(UID)){
  
  print(i)
  
  e <- get.data.frame(g.list[[i]])
  e$yr_month = paste(UID[i])
  edgeWeights.list[[i]] <- e
}

# Unlist all edge metrics (edgeWeights.list)
allEdges <- rbindlist(edgeWeights.list)

# Look at distribution of edge weights
hist(allEdges$weight) # Most of them close to 1.0!

# Save this! 
saveRDS(allEdges, "~/UWyo/PhD project/YNP-ungulate-niche-proj/Code output/individual_network_metrics/individual_edge_metrics_month.rds")
```

```{r}
#Pull metrics from nodes
# For more info on how to pull metrics from SNA: https://docs.ropensci.org/spatsoc/articles/using-in-sna.html

# Metrics:
# -> eigenvector centrality (with igraph): https://rdrr.io/cran/igraph/man/eigen_centrality.html
# -> eigenvector centrality - evcent() (with sna): https://www.rdocumentation.org/packages/sna/versions/2.6/topics/evcent
# -> strength (or weighted vertex degree): https://rdrr.io/cran/igraph/man/strength.html
# -> betweenness (with igraph): https://igraph.org/r/doc/betweenness.html
# -> betweenness (with sna): https://www.rdocumentation.org/packages/sna/versions/2.6/topics/betweenness

obs.list <- vector("list", N)

for (i in 1:length(UID)){
  
  print (i)
  
  observed <- data.table(
    
    centralityScaled = igraph::eigen_centrality(g.list[[i]], scale = TRUE)$vector, # Logical scalar, whether to scale the result to have a maximum score of one.
    centrality = igraph::eigen_centrality(g.list[[i]], scale = FALSE)$vector, # If no scaling is used then the result vector has unit length in the Euclidean norm.
    betweennessNorm = igraph::betweenness(g.list[[i]], normalized = TRUE), # If normalize = T, it seems like scores are rescaled such that they sum to 1.
    betweenness = igraph::betweenness(g.list[[i]], normalized = FALSE),
    strength = igraph::strength(g.list[[i]]), # The function graph.strength() also does the same thing!
    # Summing up the edge weights of the adjacent edges for each vertex. 
    # Be careful here, as this is relative to the number of collars that were out during that yr_seas!
    degree = igraph::degree(g.list[[i]]), # The degree of a vertex is its most basic structural property, the number of its adjacent edges.
    # Be careful here, as this is also relative to the number of collars that were out during that yr_seas!
    id = names(igraph::degree(g.list[[i]])),
    yr_month = paste(UID[i])
    
  )
  
  obs.list[[i]] <- observed
}

# Unlist all node metrics (obs.list)
allNodes <- rbindlist(obs.list)

# Look at distribution of some of the metrics:
hist(allNodes$centralityScaled)
hist(allNodes$strength)
hist(allNodes$degree)
hist(allNodes$betweennessNorm)

# Save this! 
saveRDS(allNodes, "~/UWyo/PhD project/YNP-ungulate-niche-proj/Code output/individual_network_metrics/individual_node_metrics_month.rds")
```






